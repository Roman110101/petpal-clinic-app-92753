import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import path from 'path';
import { fileURLToPath } from 'url';
import fs from 'fs';

// Google Cloud imports
import textToSpeech from '@google-cloud/text-to-speech';
import dialogflow from '@google-cloud/dialogflow';

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true }));

// Serve static files
app.use(express.static(path.join(__dirname, '../dist')));

// Google Cloud configuration
const textToSpeechClient = new textToSpeech.TextToSpeechClient({
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
  projectId: process.env.GOOGLE_CLOUD_PROJECT_ID
});

const dialogflowClient = new dialogflow.SessionsClient({
  keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS,
  projectId: process.env.GOOGLE_CLOUD_PROJECT_ID
});

// Dialogflow configuration
const DIALOGFLOW_PROJECT_ID = process.env.GOOGLE_CLOUD_PROJECT_ID;
const DIALOGFLOW_LANGUAGE_CODE = 'ru';

// Store for session data
const sessions = new Map();

/**
 * Generate audio from text using Google Cloud Text-to-Speech
 */
async function generateAudio(text) {
  try {
    console.log('๐ต ะะตะฝะตัะธััะตะผ ะฐัะดะธะพ ะดะปั ัะตะบััะฐ:', text.substring(0, 50) + '...');
    
    const request = {
      input: { text: text },
      voice: {
        languageCode: 'ru-RU',
        name: 'ru-RU-Wavenet-C', // ะะตะฝัะบะธะน ะณะพะปะพั WaveNet ะดะปั ััััะบะพะณะพ
        ssmlGender: 'FEMALE'
      },
      audioConfig: {
        audioEncoding: 'MP3',
        speakingRate: 0.9,
        pitch: 1.05,
        volumeGainDb: 2.0
      }
    };

    const [response] = await textToSpeechClient.synthesizeSpeech(request);
    
    return response.audioContent;
  } catch (error) {
    console.error('โ ะัะธะฑะบะฐ ะณะตะฝะตัะฐัะธะธ ะฐัะดะธะพ:', error);
    throw error;
  }
}

/**
 * Get response from Dialogflow
 */
async function getDialogflowResponse(sessionId, text) {
  try {
    console.log('๐ค ะัะฟัะฐะฒะปัะตะผ ะทะฐะฟัะพั ะฒ Dialogflow:', text.substring(0, 50) + '...');
    
    const sessionPath = dialogflowClient.projectAgentSessionPath(
      DIALOGFLOW_PROJECT_ID,
      sessionId
    );

    const request = {
      session: sessionPath,
      queryInput: {
        text: {
          text: text,
          languageCode: DIALOGFLOW_LANGUAGE_CODE,
        },
      },
    };

    const [responses] = await dialogflowClient.detectIntent(request);
    const result = responses[0].queryResult;
    
    console.log('โ ะัะฒะตั ะพั Dialogflow:', result.fulfillmentText);
    
    return {
      text: result.fulfillmentText,
      intent: result.intent.displayName,
      confidence: result.intentDetectionConfidence
    };
  } catch (error) {
    console.error('โ ะัะธะฑะบะฐ Dialogflow:', error);
    
    // Fallback response
    return {
      text: "ะะทะฒะธะฝะธัะต, ั ะฝะต ะฟะพะฝัะปะฐ ะฒะฐั ะฒะพะฟัะพั. ะะพะถะตัะต ะฟะตัะตัะพัะผัะปะธัะพะฒะฐัั?",
      intent: "fallback",
      confidence: 0
    };
  }
}

/**
 * API endpoint for voice processing
 */
app.post('/api/voice/process', async (req, res) => {
  try {
    const { text, sessionId = 'default' } = req.body;
    
    if (!text || typeof text !== 'string') {
      return res.status(400).json({ 
        error: 'ะขะตะบัั ัะพะพะฑัะตะฝะธั ะพะฑัะทะฐัะตะปะตะฝ' 
      });
    }

    console.log('๐ค ะะฑัะฐะฑะฐััะฒะฐะตะผ ะณะพะปะพัะพะฒะพะต ัะพะพะฑัะตะฝะธะต:', {
      sessionId,
      text: text.substring(0, 50) + '...'
    });

    // Get response from Dialogflow
    const dialogflowResponse = await getDialogflowResponse(sessionId, text);
    
    // Generate audio from response text
    const audioBuffer = await generateAudio(dialogflowResponse.text);
    
    // Convert buffer to base64 for transmission
    const audioBase64 = audioBuffer.toString('base64');
    
    // Store session data
    sessions.set(sessionId, {
      lastMessage: text,
      lastResponse: dialogflowResponse.text,
      timestamp: Date.now()
    });

    res.json({
      success: true,
      response: {
        text: dialogflowResponse.text,
        audio: audioBase64,
        intent: dialogflowResponse.intent,
        confidence: dialogflowResponse.confidence
      }
    });

  } catch (error) {
    console.error('โ ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ ะณะพะปะพัะพะฒะพะณะพ ัะพะพะฑัะตะฝะธั:', error);
    res.status(500).json({ 
      error: 'ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ ะณะพะปะพัะพะฒะพะณะพ ัะพะพะฑัะตะฝะธั',
      details: error.message 
    });
  }
});

/**
 * API endpoint for text-only processing (without audio)
 */
app.post('/api/voice/text', async (req, res) => {
  try {
    const { text, sessionId = 'default' } = req.body;
    
    if (!text || typeof text !== 'string') {
      return res.status(400).json({ 
        error: 'ะขะตะบัั ัะพะพะฑัะตะฝะธั ะพะฑัะทะฐัะตะปะตะฝ' 
      });
    }

    console.log('๐ฌ ะะฑัะฐะฑะฐััะฒะฐะตะผ ัะตะบััะพะฒะพะต ัะพะพะฑัะตะฝะธะต:', {
      sessionId,
      text: text.substring(0, 50) + '...'
    });

    // Get response from Dialogflow
    const dialogflowResponse = await getDialogflowResponse(sessionId, text);
    
    // Store session data
    sessions.set(sessionId, {
      lastMessage: text,
      lastResponse: dialogflowResponse.text,
      timestamp: Date.now()
    });

    res.json({
      success: true,
      response: {
        text: dialogflowResponse.text,
        intent: dialogflowResponse.intent,
        confidence: dialogflowResponse.confidence
      }
    });

  } catch (error) {
    console.error('โ ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ ัะตะบััะพะฒะพะณะพ ัะพะพะฑัะตะฝะธั:', error);
    res.status(500).json({ 
      error: 'ะัะธะฑะบะฐ ะพะฑัะฐะฑะพัะบะธ ัะตะบััะพะฒะพะณะพ ัะพะพะฑัะตะฝะธั',
      details: error.message 
    });
  }
});

/**
 * API endpoint for generating audio from text
 */
app.post('/api/voice/synthesize', async (req, res) => {
  try {
    const { text } = req.body;
    
    if (!text || typeof text !== 'string') {
      return res.status(400).json({ 
        error: 'ะขะตะบัั ะดะปั ะพะทะฒััะธะฒะฐะฝะธั ะพะฑัะทะฐัะตะปะตะฝ' 
      });
    }

    console.log('๐ต ะกะธะฝัะตะทะธััะตะผ ัะตัั ะดะปั ัะตะบััะฐ:', text.substring(0, 50) + '...');

    // Generate audio from text
    const audioBuffer = await generateAudio(text);
    
    // Convert buffer to base64 for transmission
    const audioBase64 = audioBuffer.toString('base64');
    
    res.json({
      success: true,
      audio: audioBase64
    });

  } catch (error) {
    console.error('โ ะัะธะฑะบะฐ ัะธะฝัะตะทะฐ ัะตัะธ:', error);
    res.status(500).json({ 
      error: 'ะัะธะฑะบะฐ ัะธะฝัะตะทะฐ ัะตัะธ',
      details: error.message 
    });
  }
});

/**
 * Health check endpoint
 */
app.get('/api/health', (req, res) => {
  res.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    services: {
      dialogflow: 'connected',
      textToSpeech: 'connected'
    }
  });
});

/**
 * Serve React app for all other routes
 */
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, '../dist/index.html'));
});

// Start server
app.listen(PORT, () => {
  console.log(`๐ ะกะตัะฒะตั ะทะฐะฟััะตะฝ ะฝะฐ ะฟะพััั ${PORT}`);
  console.log(`๐ API ะดะพัััะฟะตะฝ ะฟะพ ะฐะดัะตัั: http://localhost:${PORT}/api`);
  console.log(`๐ค ะะพะปะพัะพะฒะพะน ะฐััะธััะตะฝั: http://localhost:${PORT}`);
  console.log('๐ ะะต ะทะฐะฑัะดััะต ะฝะฐัััะพะธัั ะฟะตัะตะผะตะฝะฝัะต ะพะบััะถะตะฝะธั!');
});

export default app;